{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\nam\\anaconda3\\lib\\site-packages (from selenium) (1.25.8)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('.\\driver\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfumes = []\n",
    "informations = []\n",
    "notes = []\n",
    "# reviews = [] \n",
    "\n",
    "# for num in range(26120000, 26160654 + 1):\n",
    "for num in range(26120000, 26120010 + 1):\n",
    "    driver.get(f\"http://www.basenotes.net/ID{num}.html\")\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    \n",
    "    ##### 이름, 연도, 이미지\n",
    "    find_div = soup.find(\"h1\", class_=\"fragranceheading\")\n",
    "    try:\n",
    "        perfume_subhead = find_div.find(\"span\", \"subhead\")\n",
    "    except: \n",
    "        continue\n",
    "    temp = dict()\n",
    "    temp[\"id\"] = num \n",
    "    temp[\"name\"] = find_div.find(\"span\").get_text()\n",
    "    temp[\"year\"] = perfume_subhead.find(\"a\").get_text()\n",
    "    temp[\"src\"] = perfume_subhead.find(\"img\")[\"src\"]\n",
    "    perfumes.append(temp)\n",
    "\n",
    "    \n",
    "    ##### 성별, 생산, 회사\n",
    "    find_div = soup.find(\"div\", class_ = \"dirwrap50 frontdiv\")\n",
    "    table = find_div.find('table')\n",
    "    df = pd.read_html(str(table))\n",
    "    temp = dict()\n",
    "    for d in df[0].values[1:]:\n",
    "        if d[0] in \"Gender\":\n",
    "            temp[\"gender\"] = d[2]\n",
    "        if d[0] in \"Availability\":\n",
    "            temp[\"availability\"] = d[2]\n",
    "        if d[0] in \"House\":\n",
    "            temp[\"house\"] = d[2]\n",
    "    temp[\"perfume_id\"] = num\n",
    "    informations.append(temp)\n",
    "\n",
    "    \n",
    "    ###### 향수 성분\n",
    "    find_div = soup.find(\"div\", class_=\"dirright50\")\n",
    "    find_ul = find_div.find_all(\"ul\")\n",
    "    temp = dict()\n",
    "    for idx, link in enumerate(find_ul):\n",
    "        for a_tag in link.find_all(\"a\"):\n",
    "            if idx == 0:\n",
    "                temp[\"top\"] = a_tag.get_text()\n",
    "            elif idx == 1:\n",
    "                temp[\"heart\"] = a_tag.get_text()\n",
    "            elif idx == 2:\n",
    "                temp[\"base\"] = a_tag.get_text()\n",
    "    temp[\"perfume_id\"] = num\n",
    "    notes.append(temp)    \n",
    "    \n",
    "    \n",
    "    ####### 리뷰\n",
    "#     find_good_reviews = soup.find_all(\"div\", class_ = \"reviewmain review3\")\n",
    "#     find_neutral_reviews = soup.find_all(\"div\", class_ = \"reviewmain review2\")\n",
    "#     find_bad_reviews = soup.find_all(\"div\", class_ = \"reviewmain review1\")\n",
    "#     for idx, good_reviews in enumerate(find_good_reviews):\n",
    "#         for review in good_reviews.find_all(\"div\", class_=\"reviewblurb\"):\n",
    "#             text = review.get_text()\n",
    "#             reviews.append({'review': text, 'react': 'good', 'perfume_id': num})\n",
    "#     for idx, neutral_reviews in enumerate(find_neutral_reviews):\n",
    "#         for review in neutral_reviews.find_all(\"div\", class_=\"reviewblurb\"):\n",
    "#             text = review.get_text()\n",
    "#             reviews.append({'review': text, 'react': 'neutral', 'perfume_id': num})\n",
    "#     for idx, bad_reviews in enumerate(find_bad_reviews):\n",
    "#         for review in bad_reviews.find_all(\"div\", class_=\"reviewblurb\"):\n",
    "#             text = review.get_text()\n",
    "#             reviews.append({'review': text, 'react': 'bad', 'perfume_id': num})\n",
    "\n",
    "# data = {\"perfumes\": perfumes, \"informations\": informations, 'notes': notes, \"reviews\": reviews }\n",
    "\n",
    "data = {\"perfumes\": perfumes, \"informations\": informations, 'notes': notes }\n",
    "\n",
    "with open('./data/test2.json', 'w', encoding=\"utf-8\") as make_file:\n",
    "    json.dump(data, make_file, ensure_ascii=False, indent=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
